<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>利用随机自注意力机制的序列推荐</title>
      <link href="/2023/01/02/%E5%88%A9%E7%94%A8%E9%9A%8F%E6%9C%BA%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E5%BA%8F%E5%88%97%E6%8E%A8%E8%8D%90/"/>
      <url>/2023/01/02/%E5%88%A9%E7%94%A8%E9%9A%8F%E6%9C%BA%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E5%BA%8F%E5%88%97%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<p>序列推荐中有transformer作基础，有很好的表现能力，但是目前存在的问题就是，用户在现实世界中的行为是不确定的，</p><span id="more"></span><p><strong>存疑为什么是不确定的</strong></p><p>BRP损失函数对正项和抽样负项没有约束，这误导了优化。</p><p><strong>BPR衡量的是用户对正面物品和随机抽样的负面物品的偏好得分之间的差异。</strong></p><p>本篇文章提出了新的随机自我注意来客服这些问题。</p><p>将每个项目嵌入为随机高斯分布，因为它的协方差编码既有不确定性。</p><p><strong>协方差针对的是多个变量之间。</strong></p><p><strong>高斯分布即正态分布</strong></p><p>设计了一个Wasserstein self-attention模块来描述序列中项目- 项目位置关系，有效的将不确定性纳入模型训练中。</p><p>此外对排序损失引入了新的正则化项，保证了正负项之间的不相似性。</p><p>主要突出在不确定性上，摘要里主要提到了嵌入曾的高斯分布</p><p>和一个随机模块</p><p>尽管自注意力在transform上有很好的成功，但是都是基于点积的自注意方法未能融合：1.动态不确定性2.协作传递性</p><p>现有的序列推荐方法假定动态用户的兴趣是确定的。用户嵌入是潜在空间中的固定向量，不足以代表各种各样的用户兴趣</p><p>例如，在图书推荐中，对科幻、言情和传记感兴趣的用户比对惊悚、恐怖和奇幻感兴趣的用户更具不确定性。</p><p>动态不确定性是我们在顺序环境中建模用户兴趣时的一个关键组成部分。</p><p>我的理解：序列推荐都是根据以往的事件直接确定用户的兴趣，因此说兴趣是确定的 ，但是如上面的例子，用户可能会对意料之外的感兴趣，因为用户是动态的不是确定的，因此要考虑用户的不确定性。</p><p>协作传递性：</p><p>我的理解：就是协同，通过物品对的相似度寻找其他相似的物品</p><p>可以解决冷启动问题</p><p>定项目转换对(ix→iy)和(iy→iz)，ix和iy彼此接近，因此对于iy和iz，根据协同传递性，ix和iz也应该接近。</p><p>然而，现有的点积自关注并不能实现这种协作紧密性。例如，给定ix &#x3D; [0,2]， iy &#x3D; [1,1]， iz &#x3D;[2,0]的嵌入，(ix, iy)和(iy, iz)的点积都为2，但ix和iz之间的点积为0，因为ix和iz的过渡对未被观察到。对于不受欢迎的项目(项目冷启动问题)，这个问题会变得更严重，因为冷启动项目的数据不足限制了协作邻居集。</p><p>本框架分为三部分：</p><p>1.随机嵌入</p><p>​建模为带有随机嵌入的高斯分布，包括了均值（用于基本兴趣）和协方差（用于兴趣的可变性）嵌入</p><p>2.Wasserstein自注意</p><p>使用距离作为度量，抛弃了点积</p><p>可以缩放项目之间的Wasserstein距离来测量注意力。</p><p>3.BPR损失函数</p><p>为消除正负相似性，引入了一个新的正则化项。</p><p>在自注意力推荐中</p><p>自注意力的特点是：序列中的项目是相关的，但是不同的位置有不同的重要性，具体来说对于动作序列Su和最大序列长度n需要定义最近的n个序列行为</p><p>最后定义出的 序列矩阵嵌入为：<img src="D:\software\Typora\typora-note\image\image-20230101233548580.png" alt="image-20230101233548580"></p><p>其中m是初始的最近的n个序列向量，p是可训练的向量。</p><p>我们提出了随机嵌入来考虑动态不确定性信息，并引入了一种新的Wasserstein自注意层来捕获协作传递性信号。我们引入了ELU激活的前馈网络，并保证了协方差的正定性。</p><p><img src="/.%5Cimage%5Cimage-20230101234303982.png" alt="image-20230101234303982"></p><p>W自注意力层</p><p>A表示为一个自注意矩阵n*n，每个值表示每个物品的注意权重</p><p>利用传统的自注意力求取</p><p><img src="D:\software\Typora\typora-note\image\image-20230101235107409.png" alt="image-20230101235107409"></p><p>但是我们用新的W距离来衡量物品之间的相关度</p><p><img src="D:\software\Typora\typora-note\image\image-20230101235355793.png" alt="image-20230101235355793"></p><p>首先这个距离优点</p><p>1.表示的是分布之间的距离，度量了不确定性信息的项目的不相似的能力</p><p>2.满足三角形不等式，可以在序列建模中归纳协同传递性</p><p>3.稳定训练</p><p>Wasserstein注意聚合。在序列的每个位置上，项目的输出嵌入是前几个步骤中嵌入的加权和，其中权重是标准化的注意值≈A，为:</p><p><img src="D:\software\Typora\typora-note\image\image-20230101235748020.png" alt="image-20230101235748020"></p><p>输出的z运用了高斯分布发线性组合</p><p>因此可加，新的生成随机序列z包含了具体有不确定性的历史序列信号。</p><p><img src="D:\software\Typora\typora-note\image\image-20230102000121301.png" alt="image-20230102000121301"></p><p>A表示的是k与t的距离，v表示的是k的向量，相乘自然是新的Zt向量。</p><p><strong>共享项嵌入策略来减小模型大小和过拟合的风险</strong>？</p><p>通过对分数进行升序排序来生成前n个推荐列表。</p><p>BRP损失</p><p><img src="D:\software\Typora\typora-note\image\image-20230102001706015.png" alt="image-20230102001706015"></p>]]></content>
      
      
      
        <tags>
            
            <tag> --论文 --序列推荐 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
